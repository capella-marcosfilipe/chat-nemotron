# Nemotron Chat API

_Marcos Filipe Capella_ - <https://marcoscapella.com.br> - LinkedIn: <https://www.linkedin.com/in/capella-marcosfilipe/>

---

Este Ã© um projeto pessoal para interagir com o modelo de linguagem Nemotron da NVIDIA preferencialmente nativamente em GPU local, ou via API oficial da NVIDIA como fallback.

Esta aplicaÃ§Ã£o Ã© pensada como microsserviÃ§o para ser integrada em outras aplicaÃ§Ãµes, como chatbots, assistentes virtuais, ou qualquer sistema que se beneficie de capacidades avanÃ§adas de processamento de linguagem natural.

**Arquitetura:** Sistema assÃ­ncrono baseado em filas (RabbitMQ) com workers dedicados para GPU e API, usando Redis para cache e gerenciamento de jobs.

Aceito contribuiÃ§Ãµes e sugestÃµes para melhorias! Entre em contato comigo via LinkedIn ou e-mail > <marcoscapella@outlook.com>. Estou sempre atento a novas ideias e colaboraÃ§Ãµes.

---

## ğŸš€ InÃ­cio RÃ¡pido

### 1. PrÃ©-requisitos

- **Python 3.10+**
- **Docker Desktop** (para Redis e RabbitMQ)
- **NVIDIA API Key** (gratuita em <https://build.nvidia.com>)

### 2. Setup em 4 Passos

```powershell
# 1. Clonar e entrar no diretÃ³rio
cd nemotron-chat-microservice

# 2. Criar ambiente virtual e instalar dependÃªncias
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 3. Configurar variÃ¡veis de ambiente
copy .env.example .env
# Edite .env e adicione sua NVIDIA_API_KEY

# 4. Iniciar infraestrutura (Redis + RabbitMQ)
docker-compose up -d
```

### 3. Executar a AplicaÃ§Ã£o (3 terminais)

**Terminal 1 - API:**

```powershell
.venv\Scripts\Activate.ps1
python app/main.py
```

**Terminal 2 - Worker API:**

```powershell
.venv\Scripts\Activate.ps1
python app/run_api_worker.py
```

**Terminal 3 (Opcional) - Worker GPU:**

```powershell
.venv\Scripts\Activate.ps1
python app/run_gpu_worker.py  # Apenas se tiver GPU NVIDIA
```

### 4. Testar

```powershell
# Abrir Swagger UI
start http://localhost:8000/docs

# Ou executar teste automatizado
python test_flow.py
```

---

## ğŸ“š DocumentaÃ§Ã£o Completa

- **[Guia de Desenvolvimento e Debug](DEV_GUIDE.md)** - Setup detalhado, debug com VS Code, troubleshooting
- **[Swagger UI](http://localhost:8000/docs)** - DocumentaÃ§Ã£o interativa da API
- **[RabbitMQ Management](http://localhost:15672)** - Monitorar filas (user: guest, pass: guest)

---

## ğŸ¯ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚ â† Recebe requisiÃ§Ãµes HTTP
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ POST /chat/auto  â†’ Roteia para GPU ou API
       â”œâ”€â†’ POST /chat/gpu   â†’ ForÃ§a GPU queue
       â””â”€â†’ POST /chat/api   â†’ ForÃ§a API queue
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RabbitMQ Queues              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GPU Queue  â”‚  â”‚  API Queue  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚GPU Worker  â”‚   â”‚ API Worker â”‚
    â”‚(Local GPU) â”‚   â”‚(NVIDIA API)â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Redis     â”‚ â† Armazena status dos jobs
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluxo:**

1. Cliente envia POST para `/chat/auto`, `/chat/gpu` ou `/chat/api`
2. API retorna `job_id` imediatamente (status: PENDING)
3. Mensagem Ã© publicada na fila apropriada (GPU ou API)
4. Worker consome mensagem e processa (status: PROCESSING)
5. Resultado Ã© salvo no Redis (status: COMPLETED ou FAILED)
6. Cliente consulta GET `/chat/status/{job_id}` para obter resultado

---

## Requisitos MÃ­nimos

- Python 3.10+
- 2GB RAM
- API Key da NVIDIA (gratuita em <https://build.nvidia.com>)

### Dica para desenvolvimento/debug

Para depuraÃ§Ã£o mais rÃ¡pida, prefira ambientes virtuais criados com `python -m venv .venv` ao invÃ©s de conda. O venv inicializa mais rÃ¡pido e consome menos recursos.

## Endpoints disponÃ­veis

- `POST /chat/auto`: Interage com o modelo Nemotron preferencialmente em GPU local, ou via API oficial da NVIDIA como fallback (assÃ­ncrono)
- `POST /chat/gpu`: Interage com o modelo Nemotron exclusivamente em GPU local (assÃ­ncrono)
- `POST /chat/api`: Interage com o modelo Nemotron exclusivamente via API oficial da NVIDIA (assÃ­ncrono)
- `GET /chat/status/{job_id}`: Consulta o status e resultado de um job
- `GET /chat/info`: Fornece informaÃ§Ãµes sobre os modos disponÃ­veis (GPU local e API oficial da NVIDIA)

Swagger UI disponÃ­vel em `/docs` para testes interativos.

## Formato das requisiÃ§Ãµes

As requisiÃ§Ãµes para os endpoints de chat (`/chat/auto`, `/chat/gpu`, `/chat/api`) devem ser feitas no formato JSON com a seguinte estrutura mÃ­nima:

```json
{
  "message": "Sua mensagem aqui"
}
```

Outros campos opcionais podem ser incluÃ­dos conforme necessÃ¡rio, como contexto adicional ou parÃ¢metros de configuraÃ§Ã£o. Como no exemplo completo abaixo:

```json
{
  "message": "OlÃ¡, como vocÃª estÃ¡?",
  "max_tokens": 256,
  "temperature": 0.7,
  "use_reasoning": true
}
```

### Resposta AssÃ­ncrona (imediata)

A API retorna imediatamente com um job_id:

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "idempotency_key": "..."
}
```

### Consultar Status do Job

Use o endpoint `/chat/status/{job_id}`:

**Processando:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "created_at": "2026-02-02T10:30:00Z",
  "result": null
}
```

**Completado:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "created_at": "2026-02-02T10:30:00Z",
  "result": {
    "response": "Resposta do modelo aqui",
    "mode": "api",
    "latency_ms": 1250.5
  }
}
```

**Falha:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "failed",
  "created_at": "2026-02-02T10:30:00Z",
  "error": "DescriÃ§Ã£o do erro"
}
```
