# Nemotron Chat API

_Marcos Filipe Capella_ - <https://marcoscapella.com.br> - LinkedIn: <https://www.linkedin.com/in/capella-marcosfilipe/>

---

Este Ã© um projeto pessoal para interagir com o modelo de linguagem Nemotron da NVIDIA preferencialmente nativamente em GPU local, ou via API oficial da NVIDIA como fallback.

Esta aplicaÃ§Ã£o Ã© pensada como microsserviÃ§o para ser integrada em outras aplicaÃ§Ãµes, como chatbots, assistentes virtuais, ou qualquer sistema que se beneficie de capacidades avanÃ§adas de processamento de linguagem natural.

**Arquitetura:** Sistema assÃ­ncrono baseado em filas (RabbitMQ) com workers dedicados para GPU e API, usando Redis para cache e gerenciamento de jobs.

Aceito contribuiÃ§Ãµes e sugestÃµes para melhorias! Entre em contato comigo via LinkedIn ou e-mail > <marcoscapella@outlook.com>. Estou sempre atento a novas ideias e colaboraÃ§Ãµes.

---

## ğŸ¯ Arquitetura

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚ â† Recebe requisiÃ§Ãµes HTTP
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â†’ POST /chat?mode={auto|gpu|api}
           â”‚
           â”œâ”€â†’ mode=auto  â†’ Roteia para GPU ou API
           â”œâ”€â†’ mode=gpu   â†’ ForÃ§a GPU queue
           â””â”€â†’ mode=api   â†’ ForÃ§a API queue
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RabbitMQ Queues              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GPU Queue  â”‚  â”‚  API Queue  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚GPU Worker  â”‚   â”‚ API Worker â”‚
    â”‚(Local GPU) â”‚   â”‚(NVIDIA API)â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Redis     â”‚ â† Armazena status dos jobs
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluxo:**

1. Cliente envia POST para `/chat?mode={auto|gpu|api}`
2. API retorna `job_id` imediatamente (status: PENDING)
3. Mensagem Ã© publicada na fila apropriada (GPU ou API)
4. Worker consome mensagem e processa (status: PROCESSING)
5. Resultado Ã© salvo no Redis (status: COMPLETED ou FAILED)
6. Cliente consulta GET `/chat/status/{job_id}` para obter resultado

---

## Requisitos MÃ­nimos

- Python 3.10+
- 2GB RAM
- API Key da NVIDIA (gratuita em <https://build.nvidia.com>)

## Endpoints disponÃ­veis

- `POST /chat?mode={auto|gpu|api}`: Interage com o modelo Nemotron com modo configurÃ¡vel via query parameter (assÃ­ncrono)
  - `mode=auto` (default): Roteia para GPU local preferencialmente, ou API da NVIDIA como fallback
  - `mode=gpu`: ForÃ§a execuÃ§Ã£o exclusiva em GPU local
  - `mode=api`: ForÃ§a execuÃ§Ã£o exclusiva via API oficial da NVIDIA
- `GET /chat/status/{job_id}`: Consulta o status e resultado de um job
- `GET /chat/info`: Fornece informaÃ§Ãµes sobre os modos disponÃ­veis (GPU local e API oficial da NVIDIA)

Swagger UI disponÃ­vel em `/docs` para testes interativos.

## Formato das requisiÃ§Ãµes

As requisiÃ§Ãµes para o endpoint de chat (`POST /chat`) devem ser feitas no formato JSON com a seguinte estrutura mÃ­nima:

```json
{
  "message": "Sua mensagem aqui"
}
```

Outros campos opcionais podem ser incluÃ­dos conforme necessÃ¡rio. Exemplo completo:

```json
{
  "message": "OlÃ¡, como vocÃª estÃ¡?",
  "max_tokens": 256,
  "temperature": 0.7,
  "use_reasoning": true,
  "idempotency_key": "uuid-gerado-pelo-cliente"
}
```

**Modo de ExecuÃ§Ã£o via Query Parameter:**

```bash
# AUTO (default) - Prefere GPU, fallback para API
POST /chat
POST /chat?mode=auto

# GPU - ForÃ§a GPU local (retorna 503 se indisponÃ­vel)
POST /chat?mode=gpu

# API - ForÃ§a NVIDIA API (sempre disponÃ­vel, suporta reasoning)
POST /chat?mode=api
```

### Resposta AssÃ­ncrona (imediata)

A API retorna imediatamente com um job_id:

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "idempotency_key": "..."
}
```

### Consultar Status do Job

Use o endpoint `/chat/status/{job_id}`:

**Processando:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "created_at": "2026-02-02T10:30:00Z",
  "result": null
}
```

**Completado:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "created_at": "2026-02-02T10:30:00Z",
  "result": {
    "response": "Resposta do modelo aqui",
    "mode": "api",
    "latency_ms": 1250.5
  }
}
```

**Falha:**

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "failed",
  "created_at": "2026-02-02T10:30:00Z",
  "error": "DescriÃ§Ã£o do erro"
}
```
